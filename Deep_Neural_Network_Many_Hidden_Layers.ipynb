{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import sys\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (30pts) Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding the categorical output values to binary by adding 1's for that index and 0's otherwise\n",
    "def oneHotEncode(y):\n",
    "    enc = pd.get_dummies(y['y'])\n",
    "    return np.matrix(enc)\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs used while forward propagation\n",
    "# works with scalar, arrays and matrix as well\n",
    "# Purpose of this method is to do squishing on the linear function\n",
    "def sigmoid(z):\n",
    "    return 1./(1+np.exp(-z))\n",
    "\n",
    "# Applying Sigmoid Activation function to the hidden layer outputs used while backward propagation to get gradients\n",
    "# works with scalar, arrays and matrix as well\n",
    "# Purpose of this method is to do undo the squishing on the linear function\n",
    "def sigmoid_prime(z):\n",
    "    inv = (np.exp(-z))/(np.power((1+np.exp(-z)),2))\n",
    "    return inv\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z,0)\n",
    "    \n",
    "def relu_prime(z):\n",
    "    return np.where(z < 0, 0.0, 1.0)\n",
    "\n",
    "# Get the loss of for the training example\n",
    "def get_cost(Y, Yhat, lamda, Wl):\n",
    "    m= Y.shape[1]\n",
    "    loss = np.multiply(np.log(Yhat),Y) + np.multiply((1.-Y), np.log(1. - Yhat))\n",
    "    loss = np.sum(loss)\n",
    "    cost = -1./m * np.sum(loss) + ((lamda/(2*m)) * np.sum(np.square(Wl)))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost\n",
    "\n",
    "# Forward propagation to calculate yHat by applying activation function twice\n",
    "def forward_propagate(cache, layerCount, activationFuncs):\n",
    "    for l in range(1, layerCount+1):\n",
    "        Zl =  'Z' + str(l)\n",
    "        Al =  'A' + str(l)\n",
    "        Wl =  'W' + str(l)\n",
    "        Al1 = 'A' + str(l-1)\n",
    "        bl =  'b' + str(l)\n",
    "        cache[Zl] = np.dot(cache[Wl], cache[Al1]) + cache[bl]\n",
    "        activationFunc = activationFuncs[l] + '(cache[Zl])'\n",
    "        cache[Al] = eval(activationFunc)\n",
    "    return cache\n",
    "\n",
    "# Backward Propagation function to calculate the gradients\n",
    "def back_propagate(cache, layerCount, deactivationFuncs):\n",
    "    gradients = {}\n",
    "    m = cache['A0'].shape[1]\n",
    "    for l in xrange(layerCount, 0, -1):\n",
    "        if(l==layerCount): # is last layer\n",
    "            dZl = cache['A' + str(l)] - cache['A' + str(l+1)]    \n",
    "        else:\n",
    "            Zl = 'Z'+ str(l)\n",
    "            dZl1 = 'dZ'+str(l+1)\n",
    "            deacFunc = deactivationFuncs[l] + '(cache[Zl])'\n",
    "            actv_prime = eval(deacFunc)\n",
    "            term1 = cache['W'+str(l+1)].T\n",
    "            term2 = gradients[dZl1]\n",
    "            product = np.dot( term1, term2)\n",
    "            dZl = np.multiply(product, actv_prime) \n",
    "        gradients['dZ' + str(l)] = dZl\n",
    "        Al1 = cache['A' + str(l-1)]\n",
    "        dWl = (1./m) * np.dot(dZl, Al1.T)\n",
    "        dbl = (1./m) * np.sum(dZl, axis=1)\n",
    "        gradients['dW' + str(l)] = dWl\n",
    "        gradients['db' + str(l)] = dbl\n",
    "    return gradients  \n",
    "\n",
    "\n",
    "def gradientDescent(X, Y, YOrg, alpha, iters, hiddenLayers, layerSizes, activationFuncs, deactivationFuncs, lamda, Xtest, Ytest):  \n",
    "    \n",
    "    cache = initialize_parameters(hiddenLayers, layerSizes,activationFuncs )\n",
    "    cache['A0'] = X\n",
    "    ykey = 'A' + str(hiddenLayers+1)\n",
    "    cache[ykey] = Y\n",
    "    old_cost = sys.maxsize\n",
    "    new_cost = sys.maxsize\n",
    "    cost_history = []\n",
    "    maxTestAcc = -sys.maxsize -1\n",
    "    for i in range(iters):\n",
    "        # Call Forward propagation to calculate yHat\n",
    "        cache = forward_propagate(cache, hiddenLayers, activationFuncs)\n",
    "        old_cost = new_cost\n",
    "        Afinal = cache['A'+str(hiddenLayers)]\n",
    "        new_cost = get_cost(Y, cache['A'+str(hiddenLayers)], lamda, cache['W'+str(hiddenLayers)]) # Regularization\n",
    "        gradients = back_propagate(cache, hiddenLayers, deactivationFuncs)\n",
    "        for l in range(1,hiddenLayers+1):\n",
    "            Wl = cache['W'+str(l)]\n",
    "            gradients['dW'+str(l)] = gradients['dW'+str(l)] + (lamda/m) * Wl  # Regularization\n",
    "            Wl = Wl - alpha * gradients['dW'+str(l)]\n",
    "            cache['W'+str(l)] = Wl\n",
    "            bl = cache['b'+str(l)]\n",
    "            bl = bl - alpha * gradients['db'+str(l)]\n",
    "            cache['b'+str(l)] = bl\n",
    "        if(abs(old_cost - new_cost) < 0.00000000001):\n",
    "            print(\"breaking\" + str(old_cost) + str(new_cost))\n",
    "            break;\n",
    "        if(i%500 ==0):\n",
    "#             testcache = cache.copy()\n",
    "#             testcache['A0'] = Xtest\n",
    "#             ykey = 'A' + str(hiddenLayers+1)\n",
    "#             cache2 = forward_propagate(testcache, hiddenLayers, activationFuncs)\n",
    "#             ATestfinal = softmax(cache2['A'+str(hiddenLayers)])\n",
    "#             acc = get_accuracy(Ytest, ATestfinal)\n",
    "#             maxTestAcc = max(maxTestAcc, acc)\n",
    "            print (\"cost : \" + str(new_cost) + \" Iteration: \" + str(i))\n",
    "        cost_history.append(new_cost)\n",
    "    Afinal = softmax(Afinal) # Apply softmax to get the actual labels\n",
    "    cache['A'+str(hiddenLayers)] = Afinal\n",
    "    accuracy = get_accuracy(YOrg, Afinal)\n",
    "#     print(\"Maximum test accuracy is \" + str(maxTestAcc))\n",
    "    return cache, cost_history, new_cost, accuracy\n",
    "\n",
    "# Softmax activation function to get the probablity of the classes\n",
    "def softmax(z):\n",
    "    softMax = (np.exp(z) / np.sum(np.exp(z),axis=0))\n",
    "    softMax = np.matrix(np.argmax(softMax,axis=0)).T\n",
    "    return softMax\n",
    "\n",
    "def plotCostHistory(cost_history, alpha, i):\n",
    "     line = plt.plot(cost_history, label=alpha)\n",
    "     plt.ylabel('Cost');\n",
    "     plt.ylim( (0, 4) )\n",
    "     plt.xlabel('Iterations');\n",
    "     plt.title('Cost Progression with Iterations for different learning rates')\n",
    "     plt.legend()\n",
    "        \n",
    "def get_accuracy(Y, Ypred):\n",
    "    Y = np.matrix(Y)\n",
    "    numcorrect = 0\n",
    "    for (x,y) in zip(Ypred,Y):\n",
    "        if(x[0]==y[0]):\n",
    "            numcorrect+=1\n",
    "    accuracy=numcorrect*100.0/len(Y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the training data\n",
    "data_train = pd.read_csv('exam1_train.csv', sep=\",\", encoding='utf-8', header='infer')\n",
    "# Remove the un-necessary column\n",
    "df_train = data_train.drop('Unnamed: 0',axis=1)\n",
    "m = df_train.shape[0]\n",
    "\n",
    "y_train = pd.DataFrame(df_train['y'])\n",
    "X_train = df_train.drop(['y'], axis=1)\n",
    "\n",
    "X_train_mat = np.matrix(X_train).T\n",
    "y_train_mat = oneHotEncode(y_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y\n",
      "202  4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eb66950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the test data\n",
    "data_test = pd.read_csv('exam1_test.csv', sep=\",\", encoding='utf-8', header='infer')\n",
    "# Remove the un-necessary column\n",
    "df_test = data_test.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "y_test = pd.DataFrame(df_test['y'])\n",
    "X_test = df_test.drop(['y'], axis=1)\n",
    "\n",
    "X_test_mat = np.matrix(X_test).T\n",
    "y_test_mat = oneHotEncode(y_test).T\n",
    "\n",
    "# Plot the selected pixel\n",
    "num = 202\n",
    "pixels = np.array(X_test[num:num+1], dtype='uint8')\n",
    "print(y_test[num:num+1])\n",
    "pixels = pixels.reshape((20, 20)).T\n",
    "plt.imshow(pixels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (10pts) Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize weights // TODO - change the initialization method\n",
    "\n",
    "np.random.seed(1) # Setting random seed to 1\n",
    "def initialize_parameters(hiddenLayers, layerSizes, activationFuncs):\n",
    "    cache = {}\n",
    "    for l in range(1,hiddenLayers+1):\n",
    "        Wl = 'W' + str(l)\n",
    "        bl = 'b' + str(l)\n",
    "        if(activationFuncs[l]=='sigmoid'):\n",
    "            print('activation is sigmoid for layer ' + str(l))\n",
    "            cache[Wl] =  np.random.randn(layerSizes[l], layerSizes[l-1]) * np.sqrt(2./layerSizes[l-1])\n",
    "            cache[bl] =  np.zeros((layerSizes[l],1))\n",
    "        elif(activationFuncs[l]=='relu'):\n",
    "            print('activation is relu for layer ' + str(l))\n",
    "            cache[Wl] =  np.random.randn(layerSizes[l], layerSizes[l-1]) * (2./np.sqrt(layerSizes[l-1]))\n",
    "            cache[bl] =  np.zeros((layerSizes[l],1))\n",
    "        else:\n",
    "            print('activation is random for layer ' + str(l))\n",
    "            cache[Wl] =  np.random.randn(layerSizes[l], layerSizes[l-1]) * 0.01 ## Random\n",
    "            cache[bl] =  np.zeros((layerSizes[l],1))\n",
    "        l=l+1\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. (30pts) Deep Neural Network model with more than 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of hidden layers including output layer are - 3\n"
     ]
    }
   ],
   "source": [
    "# Defining Hyperparameters\n",
    "hiddenLayers = 3\n",
    "layerSizes = [400, 100, 40, 10] # As specified in assignment requirements, can have as many hidden layers\n",
    "print(\" Number of hidden layers including output layer are - \" + str(hiddenLayers))\n",
    "activationFuncs = ['', 'relu', 'relu', 'sigmoid']\n",
    "deactivationFuncs = ['', 'relu_prime', 'relu_prime', 'sigmoid_prime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. (10pts) Predictions\n",
    "\n",
    "### 6. (20pts) Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimization function to check cost propagartion for different learning rates\n",
    "def optimize():\n",
    "    lamdas = [11]\n",
    "    alpha = [0.4]\n",
    "    i=0\n",
    "    scores = pd.DataFrame(columns=['alpha','cache','accuracy', 'lamda'])\n",
    "    print('*****************Training Data*********************')\n",
    "    for l in lamdas:\n",
    "        for a in alpha:\n",
    "            cache, cost_history, new_cost, acc = gradientDescent(X_train_mat, y_train_mat, y_train, a, 4841, \n",
    "                                                hiddenLayers, layerSizes, activationFuncs, deactivationFuncs, l, X_test_mat, y_test)\n",
    "            scores.loc[i] = pd.Series({'alpha':a, 'cache': cache, 'accuracy':acc, 'lamda':l})\n",
    "            print(\"Cost with \" + \"Alpha \" + str(a) + \" and lambda \" + str(l) + \" is \" + str(new_cost) + \" & \" + \"Accuracy is \" + str(acc) + \" %\")\n",
    "            plotCostHistory(cost_history, a, i)\n",
    "            i+=1\n",
    "        least_cost_comb = scores['accuracy'].idxmax()\n",
    "        alph = scores.iloc[[least_cost_comb]]['alpha'][least_cost_comb]\n",
    "        cache = scores.iloc[[least_cost_comb]]['cache'][least_cost_comb]\n",
    "        plt.show()\n",
    "        print('Best alpha is ' + str(alph))\n",
    "    return cache, alph,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Training Data*********************\n",
      "activation is relu for layer 1\n",
      "activation is relu for layer 2\n",
      "activation is sigmoid for layer 3\n",
      "cost : 8.31984513822 Iteration: 0\n",
      "cost : 0.245926664048 Iteration: 500\n",
      "cost : 0.21649801011 Iteration: 1000\n",
      "cost : 0.211823930531 Iteration: 1500\n",
      "cost : 0.19456992003 Iteration: 2000\n",
      "cost : 0.186193579473 Iteration: 2500\n",
      "cost : 0.262513098995 Iteration: 3000\n",
      "cost : 0.207482702339 Iteration: 3500\n",
      "cost : 0.196858106141 Iteration: 4000\n",
      "cost : 0.219332937514 Iteration: 4500\n",
      "Cost with Alpha 0.4 and lambda 11 is 0.187379182908 & Accuracy is 99.6571428571 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMMw8uL/A3xNG88RgRO7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1103b85d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha is 0.4\n"
     ]
    }
   ],
   "source": [
    "# Get the best combination of weights and alpha\n",
    "cache, alph,scores = optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Test Data************************\n",
      "Test Data Optimized accuracy is 94.8666666667 for alpha 0.4 and lambda 11\n",
      "*********************************************\n",
      "Max alpha is 0.4\n",
      "Max lambda is 11\n"
     ]
    }
   ],
   "source": [
    "maxAcc = -sys.maxsize -1\n",
    "maxAlpha = None\n",
    "maxLambda = None\n",
    "for index, row in scores.iterrows():\n",
    "    a = row['alpha']\n",
    "    cache = row['cache']\n",
    "    lam = row['lamda']\n",
    "    cache['A0'] = X_test_mat\n",
    "    ykey = 'A' + str(hiddenLayers+1)\n",
    "    cache2 = forward_propagate(cache, hiddenLayers, activationFuncs)\n",
    "    Afinal = softmax(cache2['A'+str(hiddenLayers)])\n",
    "    acc = get_accuracy(y_test, Afinal)\n",
    "    if(acc > maxAcc):\n",
    "        maxAcc = acc\n",
    "        maxAlpha = a\n",
    "        maxLambda = lam\n",
    "    print('*****************Test Data************************')\n",
    "    print('Test Data Optimized accuracy is ' + str(acc) + ' for alpha ' + str(a) + ' and lambda ' + str(lam))\n",
    "print(\"*********************************************\")\n",
    "#print(\"Maximum accuracy so far is \" + str(maxAcc))\n",
    "print(\"Max alpha is \" + str(maxAlpha))\n",
    "print(\"Max lambda is \" + str(maxLambda))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
